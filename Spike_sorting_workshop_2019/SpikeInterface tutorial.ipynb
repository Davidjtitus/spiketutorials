{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikeInterface tutorial\n",
    "\n",
    "\n",
    "In this tutorial, we will cover the basics of using SpikeInterface for extracellular analysis and spike sorting comparison.\n",
    "\n",
    "We will analyze a simulated dataset from MEArec (a tetrode recording) in order to show how to:\n",
    "\n",
    "- load the data with Extractors\n",
    "- load a probe file\n",
    "- preprocess the signals\n",
    "- run spike sorting with different parameters\n",
    "- curate the spike sorting output using Phy\n",
    "\n",
    "\n",
    "For this tutorial we will need the following packages:\n",
    "- MEArec\n",
    "- spikeextractors\n",
    "- spiketoolkit\n",
    "- spikewidgets\n",
    "- klusta\n",
    "- phy\n",
    "- matplotlib\n",
    "\n",
    "+ all their dependencies.\n",
    "\n",
    "To install those you can use the `requirements.txt` in this folder:\n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "If you use a conda environment, you might need to run:\n",
    "\n",
    "`ipython kernel install --user --name=tutorial`\n",
    "\n",
    "or:\n",
    "\n",
    "`conda install nb_conda_kernels` and change Kernel to the tutorial now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to download a recording. Feel free to use your own recordings as well.\n",
    "\n",
    "From this [link](https://drive.google.com/file/d/1rstuZTqWAvVIAFCaWceV20n2z8989jiG/view?usp=sharing) you can download a simulated dataset using [MEArec](https://github.com/alejoe91/MEArec).\n",
    "\n",
    "The recording was generated on a shank probe with 4 tetrodes separated by 300 $\\mu$m. It has 36 cells in total, distributed in the proximity of the 4 tetrodes. Let's first load the recordings and check them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import spikeextractors as se \n",
    "import spiketoolkit as st\n",
    "import spikewidgets as sw\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading recording and probe information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load plane information. Assuming probe is in yz plane\n"
     ]
    }
   ],
   "source": [
    "recording_file = 'recordings_36cells_four-tetrodes_30.0_10.0uV_20-06-2019_14_48.h5'\n",
    "recording = se.MEArecRecordingExtractor(recording_file, locs_2d=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RecordingExtractor` object contains information about channel ids, locations (if present), sampling frequency, traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = recording.get_channel_ids()\n",
    "fs = recording.get_sampling_frequency()\n",
    "num_chan = recording.get_num_channels()\n",
    "\n",
    "print('Channel ids', channel_ids)\n",
    "print('Sampling frequency', fs)\n",
    "print('Number of channels', num_chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the channel locations and a snippet of traces using `spikewidgets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_electrode_geometry(recording, elec_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract traces using the `get_traces()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_snippet = recording.get_traces(start_frame=int(fs*0), end_frame=int(fs*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Traces shape:', trace_snippet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_timeseries(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the spikes mainly appear separately on different tetrode. We can load the `group` information in two ways:\n",
    "\n",
    "- using the `set_channel_groups` function from `spikeextractors`\n",
    "- loading a probe file using the `load_probe_file` function\n",
    "\n",
    "Let's try the second option.\n",
    "\n",
    "Probe files are (`.prb`) also enable users to change the channel map (reorder the channels), add channel grouping properties and locations. In this case our probe file will order the channels in revers and split them in 4 groups, representing the 4 tetrodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat tetrode_16.prb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_prb = se.load_probe_file(recording, 'tetrode_16.prb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original channels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Channels after loading the probe file: [12, 13, 14, 15, 8, 9, 10, 11, 4, 5, 6, 7, 0, 1, 2, 3]\n",
      "Channel groups after loading the probe file [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print('Original channels:', recording.get_channel_ids())\n",
    "print('Channels after loading the probe file:', recording_prb.get_channel_ids())\n",
    "print('Channel groups after loading the probe file', recording_prb.get_channel_groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing recordings\n",
    "\n",
    "\n",
    "Now that the probe information is loaded we can do some preprocessing usng `spiketoolkit`.\n",
    "\n",
    "We can filter the recordings, change the reference to remove noise, discard noisy channels, whiten the data, remove stimulation artifacts, etc. (more info [here](https://spiketoolkit.readthedocs.io/en/latest/preprocessing_example.html)).\n",
    "\n",
    "Let's for example filter the recordings, remove a noisy channel, and apply common median reference (CMR). The output of preprocessing modules are also `RecordingExtractor` objects, so we can use the same basic functions for extracting traces, get channel ids and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_f = st.preprocessing.bandpass_filter(recording_prb, freq_min=300, freq_max=6000)\n",
    "recording_rm_noise = st.preprocessing.remove_bad_channels(recording_f, bad_channels=[5])\n",
    "recording_cmr = st.preprocessing.common_reference(recording_rm_noise, reference='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_f_snippet = recording_f.get_traces(start_frame=int(fs*0), end_frame=int(fs*2))\n",
    "trace_cmr_snippet = recording_cmr.get_traces(start_frame=int(fs*0), end_frame=int(fs*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing modules can be pipelined. In this example, we applied CMR after removing one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trace_f_snippet.shape)\n",
    "print(trace_cmr_snippet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Channel ids for CMR recordings', recording_cmr.get_channel_ids())\n",
    "print('Channel groups for CMR recoridng', recording_cmr.get_channel_groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike sorting\n",
    "\n",
    "We can now run spike sorting. We will use `klusta` for this demonstration and we will run spike sorting on each group separately.\n",
    "\n",
    "Let's first check the installed sorters in `spiketoolkit` to see if `klusta` is available. Then we can check the  and `klusta` default parameters.\n",
    "\n",
    "We will use the `recording_f` object, as there is no external noise and all channels are good :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.sorters.installed_sorter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.sorters.KlustaSorter.default_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the `adjacency_radius` to 50, electrodes belonging to the same tetrode are within this distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spike sorting on entire recording\n",
    "sorting_KL_all = st.sorters.run_klusta(recording_f, adjacency_radius=50)\n",
    "print('Found', len(sorting_KL_all.get_unit_ids()), 'units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37 units\n"
     ]
    }
   ],
   "source": [
    "# run spike sorting by group\n",
    "sorting_KL_split = st.sorters.run_klusta(recording_f, adjacency_radius=50, grouping_property='group')\n",
    "print('Found', len(sorting_KL_split.get_unit_ids()), 'units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spike sorting returns a `SortingExtractor` object. Let's see some of its functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Units', sorting_KL_split.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Units', sorting_KL_split.get_unit_spike_train(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `spikewidgets` functions to quickly visualize some unit features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_unit_waveforms(sorting=sorting_KL_split, recording=recording_f, unit_ids=range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_rasters(sorting_KL_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual curation\n",
    "\n",
    "To perform manual curation we will export the data to Phy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.export_to_phy(recording_f, sorting_KL_all, output_folder='phy_KL_all', grouping_property='group')\n",
    "st.postprocessing.export_to_phy(recording_f, sorting_KL_split, output_folder='phy_KL_split', grouping_property='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui phy_KL_split/params.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui phy_all/params.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After curating the results we can reload it using the `PhySortingExtractor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_KL_all_curated = se.PhySortingExtractor('phy_all/')\n",
    "sorting_KL_split_curated = se.PhySortingExtractor('phy_split/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more sorting!!!\n",
    "\n",
    "If you have other sorters installed, you can try to run them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'detect_sign': -1, 'adjacency_radius': -1, 'freq_min': 300, 'freq_max': 6000, 'filter': False, 'curation': True, 'whiten': True, 'clip_size': 50, 'detect_threshold': 3, 'detect_interval': 10, 'noise_overlap_threshold': 0.15}\n",
      "Using 2 workers.\n",
      "Using tmpdir: /tmp/tmp29i_r321\n",
      "Num. workers = 2\n",
      "Preparing /tmp/tmp29i_r321/timeseries.hdf5...\n",
      "Preparing neighborhood sorters (M=4, N=960000)...\n",
      "Neighboorhood of channel 0 has 4 channels.\n",
      "Neighboorhood of channel 1 has 4 channels.\n",
      "Detecting events on channel 2 (phase1)...\n",
      "Detecting events on channel 1 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.168180\n",
      "Elapsed time for detect on neighborhood: 0:00:00.168645\n",
      "Num events detected on channel 1 (phase1): 1227\n",
      "Computing PCA features for channel 1 (phase1)...\n",
      "Num events detected on channel 2 (phase1): 1872\n",
      "Computing PCA features for channel 2 (phase1)...\n",
      "Clustering for channel 2 (phase1)...\n",
      "Clustering for channel 1 (phase1)...\n",
      "Found 14 clusters for channel 2 (phase1)...\n",
      "Computing templates for channel 2 (phase1)...\n",
      "Found 10 clusters for channel 1 (phase1)...\n",
      "Computing templates for channel 1 (phase1)...\n",
      "Re-assigning events for channel 2 (phase1)...\n",
      "Re-assigning 216 events from 2 to 1 with dt=-24 (k=6)\n",
      "Re-assigning 2 events from 2 to 1 with dt=0 (k=12)\n",
      "Neighboorhood of channel 2 has 4 channels.\n",
      "Detecting events on channel 3 (phase1)...\n",
      "Re-assigning events for channel 1 (phase1)...\n",
      "Re-assigning 7 events from 1 to 2 with dt=-3 (k=2)\n",
      "Re-assigning 2 events from 1 to 2 with dt=-7 (k=3)\n",
      "Re-assigning 24 events from 1 to 2 with dt=0 (k=4)\n",
      "Re-assigning 21 events from 1 to 2 with dt=0 (k=6)\n",
      "Re-assigning 5 events from 1 to 2 with dt=1 (k=8)\n",
      "Re-assigning 2 events from 1 to 2 with dt=-6 (k=10)\n",
      "Neighboorhood of channel 3 has 4 channels.\n",
      "Detecting events on channel 4 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.217747\n",
      "Num events detected on channel 3 (phase1): 1230\n",
      "Computing PCA features for channel 3 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.213633\n",
      "Num events detected on channel 4 (phase1): 1306\n",
      "Computing PCA features for channel 4 (phase1)...\n",
      "Clustering for channel 3 (phase1)...\n",
      "Found 5 clusters for channel 3 (phase1)...\n",
      "Computing templates for channel 3 (phase1)...\n",
      "Clustering for channel 4 (phase1)...\n",
      "Re-assigning events for channel 3 (phase1)...\n",
      "Re-assigning 10 events from 3 to 4 with dt=1 (k=5)\n",
      "Found 9 clusters for channel 4 (phase1)...\n",
      "Computing templates for channel 4 (phase1)...\n",
      "Re-assigning events for channel 4 (phase1)...\n",
      "Re-assigning 42 events from 4 to 3 with dt=1 (k=2)\n",
      "Re-assigning 9 events from 4 to 1 with dt=-1 (k=3)\n",
      "Re-assigning 2 events from 4 to 1 with dt=-3 (k=7)\n",
      "Neighboorhood of channel 0 has 4 channels.\n",
      "Neighboorhood of channel 1 has 4 channels.\n",
      "Computing PCA features for channel 1 (phase2)...\n",
      "No duplicate events found for channel 0 in phase2\n",
      "Computing PCA features for channel 2 (phase2)...\n",
      "No duplicate events found for channel 1 in phase2\n",
      "Clustering for channel 1 (phase2)...\n",
      "Found 6 clusters for channel 1 (phase2)...\n",
      "Neighboorhood of channel 2 has 4 channels.\n",
      "Computing PCA features for channel 3 (phase2)...\n",
      "No duplicate events found for channel 2 in phase2\n",
      "Clustering for channel 2 (phase2)...\n",
      "Clustering for channel 3 (phase2)...\n",
      "Found 6 clusters for channel 2 (phase2)...\n",
      "Neighboorhood of channel 3 has 4 channels.\n",
      "Computing PCA features for channel 4 (phase2)...\n",
      "No duplicate events found for channel 3 in phase2\n",
      "Found 2 clusters for channel 3 (phase2)...\n",
      "Clustering for channel 4 (phase2)...\n",
      "Found 3 clusters for channel 4 (phase2)...\n",
      "Preparing output...\n",
      "Done with ms4alg.\n",
      "Cleaning tmpdir::::: /tmp/tmp29i_r321\n",
      "Curating\n",
      "{'detect_sign': -1, 'adjacency_radius': -1, 'freq_min': 300, 'freq_max': 6000, 'filter': False, 'curation': True, 'whiten': True, 'clip_size': 50, 'detect_threshold': 3, 'detect_interval': 10, 'noise_overlap_threshold': 0.15}\n",
      "Using 2 workers.\n",
      "Using tmpdir: /tmp/tmpbvskgdfx\n",
      "Num. workers = 2\n",
      "Preparing /tmp/tmpbvskgdfx/timeseries.hdf5...\n",
      "Preparing neighborhood sorters (M=4, N=960000)...\n",
      "Neighboorhood of channel 0 has 4 channels.\n",
      "Neighboorhood of channel 1 has 4 channels.\n",
      "Detecting events on channel 1 (phase1)...\n",
      "Detecting events on channel 2 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.164731\n",
      "Num events detected on channel 1 (phase1): 1561\n",
      "Computing PCA features for channel 1 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.164843\n",
      "Num events detected on channel 2 (phase1): 1097\n",
      "Computing PCA features for channel 2 (phase1)...\n",
      "Clustering for channel 2 (phase1)...\n",
      "Clustering for channel 1 (phase1)...\n",
      "Found 5 clusters for channel 2 (phase1)...\n",
      "Computing templates for channel 2 (phase1)...\n",
      "Re-assigning events for channel 2 (phase1)...\n",
      "Re-assigning 31 events from 2 to 3 with dt=2 (k=2)\n",
      "Re-assigning 19 events from 2 to 1 with dt=3 (k=4)\n",
      "Re-assigning 32 events from 2 to 3 with dt=1 (k=5)\n",
      "Neighboorhood of channel 2 has 4 channels.\n",
      "Detecting events on channel 3 (phase1)...\n",
      "Found 7 clusters for channel 1 (phase1)...\n",
      "Computing templates for channel 1 (phase1)...\n",
      "Re-assigning events for channel 1 (phase1)...\n",
      "Re-assigning 20 events from 1 to 4 with dt=-1 (k=1)\n",
      "Neighboorhood of channel 3 has 4 channels.\n",
      "Detecting events on channel 4 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.199169\n",
      "Num events detected on channel 3 (phase1): 980\n",
      "Computing PCA features for channel 3 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.212840\n",
      "Num events detected on channel 4 (phase1): 1554\n",
      "Computing PCA features for channel 4 (phase1)...\n",
      "Clustering for channel 3 (phase1)...\n",
      "Found 4 clusters for channel 3 (phase1)...\n",
      "Computing templates for channel 3 (phase1)...\n",
      "Re-assigning events for channel 3 (phase1)...\n",
      "Clustering for channel 4 (phase1)...\n",
      "Found 8 clusters for channel 4 (phase1)...\n",
      "Computing templates for channel 4 (phase1)...\n",
      "Re-assigning events for channel 4 (phase1)...\n",
      "Re-assigning 3 events from 4 to 3 with dt=-3 (k=3)\n",
      "Re-assigning 12 events from 4 to 1 with dt=-4 (k=6)\n",
      "Neighboorhood of channel 0 has 4 channels.\n",
      "Neighboorhood of channel 1 has 4 channels.\n",
      "Computing PCA features for channel 2 (phase2)...\n",
      "Computing PCA features for channel 1 (phase2)...\n",
      "No duplicate events found for channel 0 in phase2\n",
      "No duplicate events found for channel 1 in phase2\n",
      "Clustering for channel 2 (phase2)...\n",
      "Clustering for channel 1 (phase2)...\n",
      "Found 2 clusters for channel 2 (phase2)...\n",
      "Neighboorhood of channel 2 has 4 channels.\n",
      "Computing PCA features for channel 3 (phase2)...\n",
      "No duplicate events found for channel 2 in phase2\n",
      "Found 5 clusters for channel 1 (phase2)...\n",
      "Neighboorhood of channel 3 has 4 channels.\n",
      "Computing PCA features for channel 4 (phase2)...\n",
      "No duplicate events found for channel 3 in phase2\n",
      "Clustering for channel 3 (phase2)...\n",
      "Clustering for channel 4 (phase2)...\n",
      "Found 4 clusters for channel 3 (phase2)...\n",
      "Found 3 clusters for channel 4 (phase2)...\n",
      "Preparing output...\n",
      "Done with ms4alg.\n",
      "Cleaning tmpdir::::: /tmp/tmpbvskgdfx\n",
      "Curating\n",
      "{'detect_sign': -1, 'adjacency_radius': -1, 'freq_min': 300, 'freq_max': 6000, 'filter': False, 'curation': True, 'whiten': True, 'clip_size': 50, 'detect_threshold': 3, 'detect_interval': 10, 'noise_overlap_threshold': 0.15}\n",
      "Using 2 workers.\n",
      "Using tmpdir: /tmp/tmpy6osylpp\n",
      "Num. workers = 2\n",
      "Preparing /tmp/tmpy6osylpp/timeseries.hdf5...\n",
      "Preparing neighborhood sorters (M=4, N=960000)...\n",
      "Neighboorhood of channel 1 has 4 channels.\n",
      "Neighboorhood of channel 0 has 4 channels.\n",
      "Detecting events on channel 1 (phase1)...\n",
      "Detecting events on channel 2 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.173729\n",
      "Elapsed time for detect on neighborhood: 0:00:00.174797\n",
      "Num events detected on channel 2 (phase1): 665\n",
      "Computing PCA features for channel 2 (phase1)...\n",
      "Num events detected on channel 1 (phase1): 1445\n",
      "Computing PCA features for channel 1 (phase1)...\n",
      "Clustering for channel 2 (phase1)...\n",
      "Found 7 clusters for channel 2 (phase1)...\n",
      "Computing templates for channel 2 (phase1)...\n",
      "Clustering for channel 1 (phase1)...\n",
      "Re-assigning events for channel 2 (phase1)...\n",
      "Re-assigning 63 events from 2 to 4 with dt=-17 (k=2)\n",
      "Re-assigning 99 events from 2 to 4 with dt=-16 (k=6)\n",
      "Neighboorhood of channel 2 has 4 channels.\n",
      "Detecting events on channel 3 (phase1)...\n",
      "Found 12 clusters for channel 1 (phase1)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for detect on neighborhood: 0:00:00.343728\n",
      "Num events detected on channel 3 (phase1): 464\n",
      "Computing PCA features for channel 3 (phase1)...\n",
      "Computing templates for channel 1 (phase1)...\n",
      "Re-assigning events for channel 1 (phase1)...\n",
      "Re-assigning 8 events from 1 to 4 with dt=-1 (k=8)\n",
      "Neighboorhood of channel 3 has 4 channels.\n",
      "Clustering for channel 3 (phase1)...\n",
      "Detecting events on channel 4 (phase1)...\n",
      "Found 3 clusters for channel 3 (phase1)...\n",
      "Computing templates for channel 3 (phase1)...\n",
      "Re-assigning events for channel 3 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.221938\n",
      "Num events detected on channel 4 (phase1): 1039\n",
      "Computing PCA features for channel 4 (phase1)...\n",
      "Clustering for channel 4 (phase1)...\n",
      "Found 7 clusters for channel 4 (phase1)...\n",
      "Computing templates for channel 4 (phase1)...\n",
      "Re-assigning events for channel 4 (phase1)...\n",
      "Re-assigning 130 events from 4 to 1 with dt=-19 (k=3)\n",
      "Re-assigning 7 events from 4 to 1 with dt=-3 (k=4)\n",
      "Neighboorhood of channel 1 has 4 channels.\n",
      "Neighboorhood of channel 0 has 4 channels.\n",
      "Computing PCA features for channel 1 (phase2)...\n",
      "Computing PCA features for channel 2 (phase2)...\n",
      "No duplicate events found for channel 1 in phase2\n",
      "WARNING: found 42 of 1038 duplicate events for channel 1 in phase2\n",
      "Clustering for channel 2 (phase2)...\n",
      "Found 1 clusters for channel 2 (phase2)...\n",
      "Neighboorhood of channel 2 has 4 channels.\n",
      "Computing PCA features for channel 3 (phase2)...\n",
      "No duplicate events found for channel 2 in phase2\n",
      "Clustering for channel 3 (phase2)...\n",
      "Clustering for channel 1 (phase2)...\n",
      "Found 2 clusters for channel 3 (phase2)...\n",
      "Neighboorhood of channel 3 has 4 channels.\n",
      "Computing PCA features for channel 4 (phase2)...\n",
      "WARNING: found 144 of 716 duplicate events for channel 4 in phase2\n",
      "Found 4 clusters for channel 1 (phase2)...\n",
      "Clustering for channel 4 (phase2)...\n",
      "Found 4 clusters for channel 4 (phase2)...\n",
      "Preparing output...\n",
      "Done with ms4alg.\n",
      "Cleaning tmpdir::::: /tmp/tmpy6osylpp\n",
      "Curating\n",
      "{'detect_sign': -1, 'adjacency_radius': -1, 'freq_min': 300, 'freq_max': 6000, 'filter': False, 'curation': True, 'whiten': True, 'clip_size': 50, 'detect_threshold': 3, 'detect_interval': 10, 'noise_overlap_threshold': 0.15}\n",
      "Using 2 workers.\n",
      "Using tmpdir: /tmp/tmpx3t9vnf2\n",
      "Num. workers = 2\n",
      "Preparing /tmp/tmpx3t9vnf2/timeseries.hdf5...\n",
      "Preparing neighborhood sorters (M=4, N=960000)...\n",
      "Neighboorhood of channel 1 has 4 channels.\n",
      "Neighboorhood of channel 0 has 4 channels.\n",
      "Detecting events on channel 1 (phase1)...\n",
      "Detecting events on channel 2 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.184328\n",
      "Num events detected on channel 1 (phase1): 1090\n",
      "Elapsed time for detect on neighborhood: 0:00:00.183132\n",
      "Num events detected on channel 2 (phase1): 1482\n",
      "Computing PCA features for channel 1 (phase1)...\n",
      "Computing PCA features for channel 2 (phase1)...\n",
      "Clustering for channel 1 (phase1)...\n",
      "Clustering for channel 2 (phase1)...\n",
      "Found 6 clusters for channel 1 (phase1)...\n",
      "Found 9 clusters for channel 2 (phase1)...\n",
      "Computing templates for channel 1 (phase1)...\n",
      "Computing templates for channel 2 (phase1)...\n",
      "Re-assigning events for channel 1 (phase1)...\n",
      "Neighboorhood of channel 2 has 4 channels.\n",
      "Detecting events on channel 3 (phase1)...\n",
      "Re-assigning events for channel 2 (phase1)...\n",
      "Re-assigning 12 events from 2 to 1 with dt=-17 (k=1)\n",
      "Re-assigning 1 events from 2 to 1 with dt=4 (k=5)\n",
      "Re-assigning 9 events from 2 to 3 with dt=-1 (k=6)\n",
      "Re-assigning 73 events from 2 to 3 with dt=12 (k=7)\n",
      "Neighboorhood of channel 3 has 4 channels.\n",
      "Detecting events on channel 4 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.245579\n",
      "Num events detected on channel 3 (phase1): 1190\n",
      "Computing PCA features for channel 3 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:00.271846\n",
      "Num events detected on channel 4 (phase1): 926\n",
      "Computing PCA features for channel 4 (phase1)...\n",
      "Clustering for channel 3 (phase1)...\n",
      "Clustering for channel 4 (phase1)...\n",
      "Found 7 clusters for channel 4 (phase1)...\n",
      "Computing templates for channel 4 (phase1)...\n",
      "Re-assigning events for channel 4 (phase1)...\n",
      "Re-assigning 2 events from 4 to 3 with dt=-1 (k=3)\n",
      "Found 6 clusters for channel 3 (phase1)...\n",
      "Computing templates for channel 3 (phase1)...\n",
      "Re-assigning events for channel 3 (phase1)...\n",
      "Re-assigning 1 events from 3 to 4 with dt=1 (k=1)\n",
      "Re-assigning 2 events from 3 to 2 with dt=-3 (k=5)\n",
      "Neighboorhood of channel 1 has 4 channels.\n",
      "Neighboorhood of channel 0 has 4 channels.\n",
      "Computing PCA features for channel 1 (phase2)...\n",
      "No duplicate events found for channel 0 in phase2\n",
      "Computing PCA features for channel 2 (phase2)...\n",
      "No duplicate events found for channel 1 in phase2\n",
      "Clustering for channel 1 (phase2)...\n",
      "Clustering for channel 2 (phase2)...\n",
      "Found 4 clusters for channel 1 (phase2)...\n",
      "Neighboorhood of channel 2 has 4 channels.\n",
      "Computing PCA features for channel 3 (phase2)...\n",
      "WARNING: found 2 of 845 duplicate events for channel 3 in phase2\n",
      "Found 3 clusters for channel 2 (phase2)...\n",
      "Neighboorhood of channel 3 has 4 channels.\n",
      "Computing PCA features for channel 4 (phase2)...\n",
      "No duplicate events found for channel 3 in phase2\n",
      "Clustering for channel 4 (phase2)...\n",
      "Found 4 clusters for channel 4 (phase2)...\n",
      "Clustering for channel 3 (phase2)...\n",
      "Found 4 clusters for channel 3 (phase2)...\n",
      "Preparing output...\n",
      "Done with ms4alg.\n",
      "Cleaning tmpdir::::: /tmp/tmpx3t9vnf2\n",
      "Curating\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "sorting_MS4 = st.sorters.run_mountainsort4(recording_f, grouping_property='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorting_MS4.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.export_to_phy(recording_f, sorting_MS4, output_folder='phy_MS4', grouping_property='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui  phy_MS4/params.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_MS4_curated = se.PhySortingExtractor('phy_MS4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with ground-truth\n",
    "\n",
    "MEArec recordings are simulated, therefore we know ground truth information about the spiking times. \n",
    "We can load the ground truth `SortingExtractor` as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_gt = se.MEArecSortingExtractor(recording_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the sorting output to the ground truth information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_KL = st.comparison.compare_sorter_to_ground_truth(sorting_gt, sorting_KL_split, min_accuracy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>false_discovery_rate</th>\n",
       "      <th>miss_rate</th>\n",
       "      <th>misclassification_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt_unit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055118</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.893491</td>\n",
       "      <td>0.898810</td>\n",
       "      <td>0.993421</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.101190</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.406114</td>\n",
       "      <td>0.547059</td>\n",
       "      <td>0.611842</td>\n",
       "      <td>0.388158</td>\n",
       "      <td>0.447674</td>\n",
       "      <td>0.011628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.571942</td>\n",
       "      <td>0.935294</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>0.064706</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.897143</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.944954</td>\n",
       "      <td>0.944954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.009091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.453704</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.024691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.993631</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.801418</td>\n",
       "      <td>0.805226</td>\n",
       "      <td>0.994135</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.178649</td>\n",
       "      <td>0.082789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>0.038217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.996904</td>\n",
       "      <td>0.943005</td>\n",
       "      <td>0.054404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.919431</td>\n",
       "      <td>0.921615</td>\n",
       "      <td>0.997429</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.078385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.628623</td>\n",
       "      <td>0.628623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359019</td>\n",
       "      <td>0.033275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.753271</td>\n",
       "      <td>0.753271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237838</td>\n",
       "      <td>0.036036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.947955</td>\n",
       "      <td>0.973282</td>\n",
       "      <td>0.026718</td>\n",
       "      <td>0.051661</td>\n",
       "      <td>0.007380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.977320</td>\n",
       "      <td>0.997895</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.944681</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.995516</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.050740</td>\n",
       "      <td>0.010571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.884817</td>\n",
       "      <td>0.730022</td>\n",
       "      <td>0.269978</td>\n",
       "      <td>0.113695</td>\n",
       "      <td>0.012920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy    recall  precision  false_discovery_rate  miss_rate  \\\n",
       "gt_unit_id                                                                   \n",
       "0           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "1           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "2           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "3           0.944882  0.944882   1.000000              0.000000   0.055118   \n",
       "4           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "5           0.893491  0.898810   0.993421              0.006579   0.101190   \n",
       "6           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "7           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "8           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "9           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "10          0.406114  0.547059   0.611842              0.388158   0.447674   \n",
       "11          0.882353  0.888889   0.991736              0.008264   0.108696   \n",
       "12          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "13          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "14          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "15          0.571942  0.935294   0.595506              0.404494   0.064706   \n",
       "16          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "17          0.882022  0.897143   0.981250              0.018750   0.102273   \n",
       "18          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "19          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "20          0.944954  0.944954   1.000000              0.000000   0.054545   \n",
       "21          0.453704  0.620253   0.628205              0.371795   0.370370   \n",
       "22          0.873239  0.873239   1.000000              0.000000   0.125000   \n",
       "23          0.939759  0.945455   0.993631              0.006369   0.054545   \n",
       "24          0.801418  0.805226   0.994135              0.005865   0.178649   \n",
       "25          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "26          0.000000  0.000000   0.000000              1.000000   0.961783   \n",
       "27          0.001456  0.002740   0.003096              0.996904   0.943005   \n",
       "28          0.919431  0.921615   0.997429              0.002571   0.078385   \n",
       "29          0.628623  0.628623   1.000000              0.000000   0.359019   \n",
       "30          0.753271  0.753271   1.000000              0.000000   0.237838   \n",
       "31          0.923913  0.947955   0.973282              0.026718   0.051661   \n",
       "32          0.975309  0.977320   0.997895              0.002105   0.022449   \n",
       "33          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "34          0.944681  0.948718   0.995516              0.004484   0.050740   \n",
       "35          0.666667  0.884817   0.730022              0.269978   0.113695   \n",
       "\n",
       "            misclassification_rate  \n",
       "gt_unit_id                          \n",
       "0                         0.000000  \n",
       "1                         0.000000  \n",
       "2                         0.000000  \n",
       "3                         0.000000  \n",
       "4                         0.000000  \n",
       "5                         0.000000  \n",
       "6                         0.000000  \n",
       "7                         0.000000  \n",
       "8                         0.000000  \n",
       "9                         0.000000  \n",
       "10                        0.011628  \n",
       "11                        0.021739  \n",
       "12                        0.000000  \n",
       "13                        0.000000  \n",
       "14                        0.000000  \n",
       "15                        0.000000  \n",
       "16                        0.000000  \n",
       "17                        0.005682  \n",
       "18                        0.000000  \n",
       "19                        0.000000  \n",
       "20                        0.009091  \n",
       "21                        0.024691  \n",
       "22                        0.013889  \n",
       "23                        0.000000  \n",
       "24                        0.082789  \n",
       "25                        0.000000  \n",
       "26                        0.038217  \n",
       "27                        0.054404  \n",
       "28                        0.000000  \n",
       "29                        0.033275  \n",
       "30                        0.036036  \n",
       "31                        0.007380  \n",
       "32                        0.010204  \n",
       "33                        0.000000  \n",
       "34                        0.010571  \n",
       "35                        0.012920  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp_KL.get_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy                  0.400201\n",
       "recall                    0.426841\n",
       "precision                 0.824348\n",
       "false_discovery_rate      0.175652\n",
       "miss_rate                 0.568926\n",
       "misclassification_rate    0.010348\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp_KL.get_performance(method='pooled_with_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_MS4 = st.comparison.compare_sorter_to_ground_truth(sorting_gt, sorting_MS4, min_accuracy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>false_discovery_rate</th>\n",
       "      <th>miss_rate</th>\n",
       "      <th>misclassification_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt_unit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986014</td>\n",
       "      <td>0.986014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.020548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.034722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330709</td>\n",
       "      <td>0.023622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.445161</td>\n",
       "      <td>0.051613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.928994</td>\n",
       "      <td>0.940120</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.005952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.665385</td>\n",
       "      <td>0.945355</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>0.041885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.959677</td>\n",
       "      <td>0.959677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038168</td>\n",
       "      <td>0.053435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.701863</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>0.137405</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.033784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.855491</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.023529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.988304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.028409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.621429</td>\n",
       "      <td>0.776786</td>\n",
       "      <td>0.223214</td>\n",
       "      <td>0.350993</td>\n",
       "      <td>0.072848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.751479</td>\n",
       "      <td>0.803797</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>0.079710</td>\n",
       "      <td>0.191358</td>\n",
       "      <td>0.024691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.975758</td>\n",
       "      <td>0.975758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.711712</td>\n",
       "      <td>0.721461</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.265795</td>\n",
       "      <td>0.045752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.575472</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0.308219</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934183</td>\n",
       "      <td>0.065817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.036486</td>\n",
       "      <td>0.073569</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.880829</td>\n",
       "      <td>0.049223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.983412</td>\n",
       "      <td>0.985748</td>\n",
       "      <td>0.997596</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.014252</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.992780</td>\n",
       "      <td>0.998185</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.007005</td>\n",
       "      <td>0.029772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.959002</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.979964</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.009009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.954044</td>\n",
       "      <td>0.959335</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>0.001845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.868468</td>\n",
       "      <td>0.993814</td>\n",
       "      <td>0.873188</td>\n",
       "      <td>0.126812</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019027</td>\n",
       "      <td>0.016913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.939633</td>\n",
       "      <td>0.944591</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.054264</td>\n",
       "      <td>0.020672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy    recall  precision  false_discovery_rate  miss_rate  \\\n",
       "gt_unit_id                                                                   \n",
       "0           0.986014  0.986014   1.000000              0.000000   0.013699   \n",
       "1           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "2           0.985714  0.992806   0.992806              0.007194   0.006944   \n",
       "3           0.661290  0.661290   1.000000              0.000000   0.330709   \n",
       "4           0.500000  0.530612   0.896552              0.103448   0.445161   \n",
       "5           0.928994  0.940120   0.987421              0.012579   0.059524   \n",
       "6           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "7           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "8           0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "9           0.665385  0.945355   0.692000              0.308000   0.052356   \n",
       "10          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "11          0.933333  0.933333   1.000000              0.000000   0.065217   \n",
       "12          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "13          0.959677  0.959677   1.000000              0.000000   0.038168   \n",
       "14          0.701863  0.790210   0.862595              0.137405   0.202703   \n",
       "15          0.855491  0.891566   0.954839              0.045161   0.105882   \n",
       "16          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "17          0.988304  0.988304   1.000000              0.000000   0.011364   \n",
       "18          1.000000  1.000000   1.000000              0.000000   0.000000   \n",
       "19          0.527273  0.621429   0.776786              0.223214   0.350993   \n",
       "20          1.000000  1.000000   1.000000              0.000000   0.000000   \n",
       "21          0.751479  0.803797   0.920290              0.079710   0.191358   \n",
       "22          1.000000  1.000000   1.000000              0.000000   0.000000   \n",
       "23          0.975758  0.975758   1.000000              0.000000   0.024242   \n",
       "24          0.711712  0.721461   0.981366              0.018634   0.265795   \n",
       "25          0.575472  0.670330   0.802632              0.197368   0.308219   \n",
       "26          0.000000  0.000000   0.000000              1.000000   0.934183   \n",
       "27          0.036486  0.073569   0.067500              0.932500   0.880829   \n",
       "28          0.983412  0.985748   0.997596              0.002404   0.014252   \n",
       "29          0.990991  0.992780   0.998185              0.001815   0.007005   \n",
       "30          0.959002  0.978182   0.979964              0.020036   0.021622   \n",
       "31          0.954044  0.959335   0.994253              0.005747   0.040590   \n",
       "32          0.868468  0.993814   0.873188              0.126812   0.006122   \n",
       "33          0.000000  0.000000        NaN                   NaN   1.000000   \n",
       "34          0.980645  0.980645   1.000000              0.000000   0.019027   \n",
       "35          0.939633  0.944591   0.994444              0.005556   0.054264   \n",
       "\n",
       "            misclassification_rate  \n",
       "gt_unit_id                          \n",
       "0                         0.020548  \n",
       "1                         0.000000  \n",
       "2                         0.034722  \n",
       "3                         0.023622  \n",
       "4                         0.051613  \n",
       "5                         0.005952  \n",
       "6                         0.000000  \n",
       "7                         0.000000  \n",
       "8                         0.000000  \n",
       "9                         0.041885  \n",
       "10                        0.000000  \n",
       "11                        0.021739  \n",
       "12                        0.000000  \n",
       "13                        0.053435  \n",
       "14                        0.033784  \n",
       "15                        0.023529  \n",
       "16                        0.000000  \n",
       "17                        0.028409  \n",
       "18                        0.007042  \n",
       "19                        0.072848  \n",
       "20                        0.000000  \n",
       "21                        0.024691  \n",
       "22                        0.006944  \n",
       "23                        0.000000  \n",
       "24                        0.045752  \n",
       "25                        0.065068  \n",
       "26                        0.065817  \n",
       "27                        0.049223  \n",
       "28                        0.000000  \n",
       "29                        0.029772  \n",
       "30                        0.009009  \n",
       "31                        0.001845  \n",
       "32                        0.010204  \n",
       "33                        0.000000  \n",
       "34                        0.016913  \n",
       "35                        0.020672  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp_MS4.get_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy                  0.622790\n",
       "recall                    0.647798\n",
       "precision                 0.884729\n",
       "false_discovery_rate      0.115271\n",
       "miss_rate                 0.345840\n",
       "misclassification_rate    0.021251\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp_MS4.get_performance(method='pooled_with_average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise) Can you improve the performance with manual curation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi sorting comparison\n",
    "\n",
    "Finally, we can compare KL and SC (or more) and automatically curate the sorting output by retaining the matching units between the two (or more) sorters. We will use the `compare_multiple_sorters` function.\n",
    "The multi sorting comparison builds a graph with all the units from the different sorters, connected with their agreement score. We can use this to extract agreement sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc = st.comparison.compare_multiple_sorters(sorting_list=[sorting_KL_split, sorting_MS4], name_list=['KL', 'MS4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_agreement = msc.get_agreement_sorting(minimum_matching=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klusta units 37\n",
      "Mountainsort units 39\n",
      "Agreement units 20\n"
     ]
    }
   ],
   "source": [
    "print('Klusta units', len(sorting_KL_split.get_unit_ids()))\n",
    "print('Mountainsort units', len(sorting_MS4.get_unit_ids()))\n",
    "print('Agreement units', len(sorting_agreement.get_unit_ids()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still inspect the agreement sorting using Phy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.export_to_phy(recording_f, sorting_agreement, output_folder='phy_AGR', grouping_property='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui phy_AGR/params.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
