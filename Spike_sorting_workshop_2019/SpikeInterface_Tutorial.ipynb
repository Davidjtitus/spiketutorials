{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikeInterface Tutorial - Spike Sorting Workshop - Edinburgh 2019\n",
    "\n",
    "\n",
    "In this tutorial, we will cover the basics of using SpikeInterface for extracellular analysis and spike sorting comparison. We will be using three packages from the SpikeInterface github organization: spikeextractors, spiketoolkit, and spikewidgets.\n",
    "\n",
    "For this analysis, we will be using a simulated dataset from [MEArec](https://github.com/alejoe91/MEArec). We will show how to:\n",
    "\n",
    "- load the data with spikeextractors package\n",
    "- load a probe file\n",
    "- preprocess the signals\n",
    "- run a popular spike sorting algorithm with different parameters\n",
    "- curate the spike sorting output using Phy\n",
    "- compare with ground-truth information\n",
    "- run consensus-based spike sorting\n",
    "\n",
    "\n",
    "For this tutorial we will need the following packages:\n",
    "- spikeextractors\n",
    "- spiketoolkit\n",
    "- spikewidgets\n",
    "- MEArec\n",
    "- klusta\n",
    "- phy\n",
    "- matplotlib\n",
    "\n",
    "+ all their dependencies.\n",
    "\n",
    "To install those you can use the `requirements.txt` in this directory by running the command:\n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "If you use a conda environment, you can create the `spiketutorial` environment with:\n",
    "\n",
    "`conda env create -f environment.yml`\n",
    "\n",
    "You might need to run:\n",
    "\n",
    "`ipython kernel install --user --name=tutorial`\n",
    "\n",
    "or:\n",
    "\n",
    "`conda install nb_conda_kernels` and change Kernel to run the tutorial notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the recording\n",
    "\n",
    "First, we need to download the recording. Feel free to use your own recordings as well later on.\n",
    "\n",
    "From this Zenodo [link](https://zenodo.org/record/3256071#.XRHqhnX7Q5k), you can download the simulated dataset mentioned above. Move the dataset in the current folder.\n",
    "\n",
    "The recording was generated on a shank probe with 4 tetrodes separated by 300 $\\mu$m. It has 36 cells in total, distributed in the proximity of the 4 tetrodes. The recording is 30 s long and there is an additive noise level of 10 $\\mu$V."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import spikeextractors as se \n",
    "import spiketoolkit as st\n",
    "import spikewidgets as sw\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading recording and probe information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_file = 'recordings_36cells_four-tetrodes_30.0_10.0uV_20-06-2019_14_48.h5'\n",
    "recording = se.MEArecRecordingExtractor(recording_file, locs_2d=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `RecordingExtractor` object extracts information about channel ids, channel locations (if present), the sampling frequency of the recording, and the extracellular traces (when prompted). The MEArecRecordingExtractor is designed specifically for MEArec datasets.\n",
    "\n",
    "Here we load information from the recording using the built-in functions from the RecordingExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = recording.get_channel_ids()\n",
    "fs = recording.get_sampling_frequency()\n",
    "num_chan = recording.get_num_channels()\n",
    "\n",
    "print('Channel ids:', channel_ids)\n",
    "print('Sampling frequency:', fs)\n",
    "print('Number of channels:', num_chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the channel locations and a snippet of traces using `spikewidgets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sw.plot_electrode_geometry(recording, elec_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_traces()` function returns a NxT numpy array where N is the number of channel ids passed in (all channel ids are passed in by default) and T is the number of frames (determined by start_frame and end_frame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_snippet = recording.get_traces(start_frame=int(fs*0), end_frame=int(fs*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Traces shape:', trace_snippet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_timeseries(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the spikes mainly appear separately on different tetrodes. Each tetrode belongs to a different `group`. We can load the `group` information in two ways:\n",
    "\n",
    "- using the `set_channel_groups` in your RecordingExtractor (manually loading group information)\n",
    "- loading a probe file using the `load_probe_file` from `spikeextractors` (automatically loading group information)\n",
    "\n",
    "Let's use the second option. Probe files (`.prb`) also enable users to change the channel map (reorder the channels) and add channel grouping properties and locations. In this case, our probe file will order the channels in reverse and split them in 4 groups, representing the 4 tetrodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat tetrode_16.prb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_prb = se.load_probe_file(recording, 'tetrode_16.prb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original channels:', recording.get_channel_ids())\n",
    "print('Channels after loading the probe file:', recording_prb.get_channel_ids())\n",
    "print('Channel groups after loading the probe file:', recording_prb.get_channel_groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing recordings\n",
    "\n",
    "\n",
    "Now that the probe information is loaded we can do some preprocessing using `spiketoolkit`.\n",
    "\n",
    "We can filter the recordings, rereference the signals to remove noise, discard noisy channels, whiten the data, remove stimulation artifacts, etc. (more info [here](https://spiketoolkit.readthedocs.io/en/latest/preprocessing_example.html)).\n",
    "\n",
    "For this notebook, let's filter the recordings, remove a noisy channel, and apply common median reference (CMR). All preprocessing modules return new `RecordingExtractor` objects that apply the underlying preprocessing function. This allows users to access the preprocessed data in the same way as the raw data.\n",
    "\n",
    "Below, we bandpass filter the recording, remove channel 5, and apply common median reference to the original recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_f = st.preprocessing.bandpass_filter(recording_prb, freq_min=300, freq_max=6000)\n",
    "recording_rm_noise = st.preprocessing.remove_bad_channels(recording_f, bad_channels=[5])\n",
    "recording_cmr = st.preprocessing.common_reference(recording_rm_noise, reference='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extractor traces from the preprocessed recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_f_snippet = recording_f.get_traces(start_frame=int(fs*0), end_frame=int(fs*2))\n",
    "trace_cmr_snippet = recording_cmr.get_traces(start_frame=int(fs*0), end_frame=int(fs*2))\n",
    "\n",
    "print(trace_f_snippet.shape)\n",
    "print(trace_cmr_snippet.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the bandpassfiltered snippets below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_timeseries(recording_f, channels=range(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Channel ids for CMR recordings:', recording_cmr.get_channel_ids())\n",
    "print('Channel groups for CMR recoridng:', recording_cmr.get_channel_groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike sorting\n",
    "\n",
    "We can now run spike sorting on the above recording. We will use `klusta` for this demonstration and we will run spike sorting on each group separately.\n",
    "\n",
    "Let's first check the installed sorters in spiketoolkit to see if klusta is available. Then we can check the `klusta` default parameters.\n",
    "\n",
    "We will sort the bandpass filtered recording (the `recording_bpf` object), as there is no external noise and all channels are good :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.sorters.installed_sorter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.sorters.KlustaSorter.default_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the `adjacency_radius` to 50 microns as electrodes belonging to the same tetrode are within this distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spike sorting on entire recording\n",
    "sorting_KL_all = st.sorters.run_klusta(recording_f, output_folder='results_all_klusta', adjacency_radius=50)\n",
    "print('Found', len(sorting_KL_all.get_unit_ids()), 'units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spike sorting by group\n",
    "sorting_KL_split = st.sorters.run_klusta(recording_f, adjacency_radius=50, \n",
    "                                         output_folder='results_split_klusta', grouping_property='group')\n",
    "print('Found', len(sorting_KL_split.get_unit_ids()), 'units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spike sorting returns a `SortingExtractor` object. Let's see some of its functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Units', sorting_KL_split.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Units', sorting_KL_split.get_unit_spike_train(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `spikewidgets` functions to quickly visualize some unit features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_unit_waveforms(sorting=sorting_KL_split, recording=recording_f, unit_ids=range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_rasters(sorting_KL_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual curation\n",
    "\n",
    "To perform manual curation we will export the data to Phy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.export_to_phy(recording_f, sorting_KL_all, output_folder='phy_KL_all', grouping_property='group')\n",
    "st.postprocessing.export_to_phy(recording_f, sorting_KL_split, output_folder='phy_KL_split', grouping_property='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui phy_KL_split/params.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui phy_all/params.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After curating the results we can reload it using the `PhySortingExtractor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_KL_all_curated = se.PhySortingExtractor('phy_all/')\n",
    "sorting_KL_split_curated = se.PhySortingExtractor('phy_split/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more spike sorting!\n",
    "\n",
    "If you have other sorters installed, you can try to run them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "sorting_MS4 = st.sorters.run_mountainsort4(recording_f, grouping_property='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorting_MS4.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.export_to_phy(recording_f, sorting_MS4, output_folder='phy_MS4', grouping_property='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui  phy_MS4/params.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_MS4_curated = se.PhySortingExtractor('phy_MS4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with ground-truth\n",
    "\n",
    "MEArec recordings are simulated, therefore we know ground truth information about the spiking times. \n",
    "We can load the ground truth `SortingExtractor` as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_gt = se.MEArecSortingExtractor(recording_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the sorting output to the ground truth information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_KL = st.comparison.compare_sorter_to_ground_truth(sorting_gt, sorting_KL_split, min_accuracy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_KL.get_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_KL.get_performance(method='pooled_with_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_MS4 = st.comparison.compare_sorter_to_ground_truth(sorting_gt, sorting_MS4, min_accuracy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_MS4.get_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_MS4.get_performance(method='pooled_with_average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise) Can you improve the performance with manual curation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-sorting comparison\n",
    "\n",
    "Finally, we can compare KL and SC (or more) and automatically curate the sorting output by retaining the matching units between the two (or more) sorters. We will use the `compare_multiple_sorters` function.\n",
    "The multi sorting comparison builds a graph with all the units from the different sorters, connected with their agreement score. We can use this to extract agreement sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc = st.comparison.compare_multiple_sorters(sorting_list=[sorting_KL_split, sorting_MS4], name_list=['KL', 'MS4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_agreement = msc.get_agreement_sorting(minimum_matching=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Klusta units', len(sorting_KL_split.get_unit_ids()))\n",
    "print('Mountainsort units', len(sorting_MS4.get_unit_ids()))\n",
    "print('Agreement units', len(sorting_agreement.get_unit_ids()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still inspect the agreement sorting using Phy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.export_to_phy(recording_f, sorting_agreement, output_folder='phy_AGR', grouping_property='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui phy_AGR/params.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
